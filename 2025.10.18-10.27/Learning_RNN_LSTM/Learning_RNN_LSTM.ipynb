{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9df1c810",
   "metadata": {},
   "source": [
    "### Learning LSTM\n",
    "\n",
    "    Author: 彭日骏\n",
    "    Time: 2025/10/14\n",
    "\n",
    "Code a RNN & LSTM to do a **MusicGenerationProject**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4e112ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee538f9b",
   "metadata": {},
   "source": [
    "#### Load data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f824335",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4c6d3f",
   "metadata": {},
   "source": [
    "**音乐语法化 (Data Representation)**\n",
    "\n",
    "Through `grammar.py` & `preprocess.py`\n",
    "\n",
    "Define different notes(音符类型)\n",
    "\n",
    "`C` (Chord tone)\n",
    "\n",
    "`S` (Scale tone)\n",
    "\n",
    "`A` (Approach tone)\n",
    "\n",
    "`R` (Rest):\n",
    "\n",
    "`X` (Arbitrary):\n",
    "\n",
    "**Token的格式:** (类型, 时值, 与上一个音符的音程)\n",
    "\n",
    "已知Tokens total = 78"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9174bf64",
   "metadata": {},
   "source": [
    "**序列化与数据准备 (Sequence Modeling)**\n",
    "\n",
    "Through `preprocess.py` & `music_utils.py` generate\n",
    "\n",
    "`Corpus(语料库)`: A long sequence contains all **Tokens**\n",
    "\n",
    "`Training dataset(训练集)`: 切分sequence为多个 Tx = 30 的序列X\n",
    "\n",
    "`Label dataset(标签集)`: 等效序列X向后平移一位得到Y,  $Y = (x_{1}, x_{2}, ..., x_{n}, x_{n+1})$ 去掉 $x_{0}$\n",
    "\n",
    "`One-Hot 编码`: 长成78维向量，对应Token的向量为对应位置1\n",
    "\n",
    "已知X = (60, 30, 78) , 被切成: 60个片段, 每个片段长30个Tokens, 每个Token对应78维向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84fa9375",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m     X, Y, N_tones = data_processing(corpus, tones_indices, \u001b[32m60\u001b[39m, \u001b[32m30\u001b[39m)   \n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (X, Y, N_tones, indices_tones)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m X, Y, n_values, indices_values = \u001b[43mload_music_utils\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mload_music_utils\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_music_utils\u001b[39m():\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     chords, abstract_grammars = \u001b[43mget_musical_data\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdata/original_metheny.mid\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     corpus, tones, tones_indices, indices_tones = get_corpus_data(abstract_grammars)\n\u001b[32m      7\u001b[39m     N_tones = \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(corpus))\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Files\\Liang-Lin-Lab\\2025.10.18-10.23\\Learning_RNN_LSTM\\preprocess.py:135\u001b[39m, in \u001b[36mget_musical_data\u001b[39m\u001b[34m(data_fn)\u001b[39m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_musical_data\u001b[39m(data_fn):\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m     measures, chords = \u001b[43m__parse_midi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    136\u001b[39m     abstract_grammars = __get_abstract_grammars(measures, chords)\n\u001b[32m    138\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m chords, abstract_grammars\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Files\\Liang-Lin-Lab\\2025.10.18-10.23\\Learning_RNN_LSTM\\preprocess.py:29\u001b[39m, in \u001b[36m__parse_midi\u001b[39m\u001b[34m(data_fn)\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# Get melody part, compress into single voice.\u001b[39;00m\n\u001b[32m     28\u001b[39m melody_stream = midi_data[\u001b[32m5\u001b[39m]     \u001b[38;5;66;03m# For Metheny piece, Melody is Part #5.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m melody1, melody2 = melody_stream.getElementsByClass(stream.Voice)\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m melody2:\n\u001b[32m     31\u001b[39m     melody1.insert(j.offset, j)\n",
      "\u001b[31mValueError\u001b[39m: not enough values to unpack (expected 2, got 0)"
     ]
    }
   ],
   "source": [
    "from music_utils import * \n",
    "from preprocess import * \n",
    "\n",
    "def load_music_utils():\n",
    "    chords, abstract_grammars = get_musical_data('data/original_metheny.mid')\n",
    "    corpus, tones, tones_indices, indices_tones = get_corpus_data(abstract_grammars)\n",
    "    N_tones = len(set(corpus))\n",
    "    X, Y, N_tones = data_processing(corpus, tones_indices, 60, 30)   \n",
    "    return (X, Y, N_tones, indices_tones)\n",
    "\n",
    "X, Y, n_values, indices_values = load_music_utils()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6264c1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Model\n",
    "class temp_predict_LSTM(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_layer_size=50, output_size=1):\n",
    "        '''\n",
    "        Def LSTM layer\n",
    "        Parameters:\n",
    "            input_size: num of features for the input sequence（输入特征的数量），只需要预测温度一个特征\n",
    "            hidden_layer_size\n",
    "            batch_first \n",
    "                        let Tensor turn to (batch_size, seq_length, input_size)\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        # Change!!!\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        '''\n",
    "        Forward Algorithm\n",
    "        LSTM need 2 of origin status hidden_layer h0 & cell_layer c0\n",
    "        '''\n",
    "        # LSTM需要初始化隐藏状态h_0 = (num_layers, batch_size, hidden_size)\n",
    "        # LSTM需要初始化隐藏状态c_0 = (num_layers, batch_size, hidden_size)\n",
    "        # 且我们需要把h0, c0移植至device\n",
    "        h0 = torch.zeros(1, input_seq.size(0), self.hidden_layer_size).to(input_seq.device)\n",
    "        c0 = torch.zeros(1, input_seq.size(0), self.hidden_layer_size).to(input_seq.device)\n",
    "\n",
    "        # lstm_out 是所有时间步的输出\n",
    "        # lstm_out 为常用Tensor张量(batch_size, seq_length, input_size) ---???为何这样处理数据更简便\n",
    "        # hidden 是最后一个时间步的隐藏状态\n",
    "        lstm_out, hidden = self.lstm(input_seq, h0)\n",
    "\n",
    "        # 只关心序列最后一个时间步的输出\n",
    "        # lstm[:, -1, :]可丢弃掉中间维度seq_length, 变为二维Tensor张量(batch_size, hidden_size)\n",
    "        predictions = self.linear(lstm_out[:, -1, :])\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d33cb5b",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
